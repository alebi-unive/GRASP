{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfdd7b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python train_reconstruction.py --dataset=sbm_200 --k=4 --smallest=True --diffusion_model=3dn0ayuq --generator_layers=4 --generator_data_channels=64 --batch_size=16 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"train_reconstruction.py\", line 10, in <module>\n",
      "    from dataset.load_data_generated import *\n",
      "  File \"/home/lcosmo/PROJECTS/Spectral-Graph-Diffusion/dataset/load_data_generated.py\", line 33, in <module>\n",
      "    from utils.eval_helper import degree_stats, clustering_stats, orbit_stats_all, eval_fraction_unique, eval_fraction_unique_non_isomorphic_valid, spectral_stats\n",
      "  File \"/home/lcosmo/PROJECTS/Spectral-Graph-Diffusion/utils/eval_helper.py\", line 16, in <module>\n",
      "    import graph_tool.all as gt\n",
      "  File \"/home/lcosmo/anaconda3/envs/graph_diffusion/lib/python3.8/site-packages/graph_tool/all.py\", line 34, in <module>\n",
      "    from graph_tool.draw import *\n",
      "  File \"/home/lcosmo/anaconda3/envs/graph_diffusion/lib/python3.8/site-packages/graph_tool/draw/__init__.py\", line 848, in <module>\n",
      "    from . cairo_draw import graph_draw, cairo_draw, \\\n",
      "  File \"/home/lcosmo/anaconda3/envs/graph_diffusion/lib/python3.8/site-packages/graph_tool/draw/cairo_draw.py\", line 1495, in <module>\n",
      "    from gi.repository import Gtk, Gdk, GdkPixbuf\n",
      "  File \"<frozen importlib._bootstrap>\", line 991, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 975, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 657, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 556, in module_from_spec\n",
      "  File \"/home/lcosmo/anaconda3/envs/graph_diffusion/lib/python3.8/site-packages/gi/importer.py\", line 146, in create_module\n",
      "    importlib.import_module('gi.repository.' + dep.split(\"-\")[0])\n",
      "  File \"/home/lcosmo/anaconda3/envs/graph_diffusion/lib/python3.8/importlib/__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1014, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 991, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 975, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 657, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 556, in module_from_spec\n",
      "  File \"/home/lcosmo/anaconda3/envs/graph_diffusion/lib/python3.8/site-packages/gi/importer.py\", line 147, in create_module\n",
      "    dynamic_module = load_overrides(introspection_module)\n",
      "  File \"/home/lcosmo/anaconda3/envs/graph_diffusion/lib/python3.8/site-packages/gi/overrides/__init__.py\", line 118, in load_overrides\n",
      "    override_mod = importlib.import_module(override_package_name)\n",
      "  File \"/home/lcosmo/anaconda3/envs/graph_diffusion/lib/python3.8/importlib/__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"/home/lcosmo/anaconda3/envs/graph_diffusion/lib/python3.8/site-packages/gi/overrides/Gdk.py\", line 484, in <module>\n",
      "    initialized, argv = Gdk.init_check(sys.argv)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python train_reconstruction.py --dataset=sbm_200 --k=4 --smallest=False --diffusion_model=3dn0ayuq --generator_layers=4 --generator_data_channels=64 --batch_size=16 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: l_cosmo. Use `wandb login --relogin` to force relogin\n",
      "wandb: wandb version 0.16.2 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n",
      "wandb: Tracking run with wandb version 0.13.4\n",
      "wandb: Run data is saved locally in ./wandb/run-20240129_172532-fltixdje\n",
      "wandb: Run `wandb offline` to turn off syncing.\n",
      "wandb: Syncing run self-cross-hugg_k-4_sm-False_dm-3dn0ayuq\n",
      "wandb: ‚≠êÔ∏è View project at https://wandb.ai/l_cosmo/graph_diffusion_recon\n",
      "wandb: üöÄ View run at https://wandb.ai/l_cosmo/graph_diffusion_recon/runs/fltixdje\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Point dim 4\n",
      "Tot #200\n",
      "compute graphs statistics\n",
      "computing degree:  tensor(0.0008)\n",
      "computing cluster:  tensor(0.0315)\n",
      "computing spectral:  tensor(0.0026)\n",
      "Point dim 4\n",
      "Tot #200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type              | Params\n",
      "------------------------------------------------\n",
      "0 | generator | PPGNGenerator     | 178 K \n",
      "1 | criterion | BCEWithLogitsLoss | 0     \n",
      "------------------------------------------------\n",
      "178 K     Trainable params\n",
      "0         Non-trainable params\n",
      "178 K     Total params\n",
      "0.713     Total estimated model params size (MB)\n",
      "/home/lcosmo/anaconda3/envs/graph_diffusion/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:489: PossibleUserWarning: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test/predict dataloaders.\n",
      "  rank_zero_warn(\n",
      "/home/lcosmo/anaconda3/envs/graph_diffusion/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:236: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 40 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/lcosmo/anaconda3/envs/graph_diffusion/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:236: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 40 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 8/10 [00:04<00:01,  1.61it/s, v_num=xdje]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lcosmo/anaconda3/envs/graph_diffusion/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:653: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n",
      "wandb: Waiting for W&B process to finish... (success).\n",
      "Error in atexit._run_exitfuncs:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lcosmo/anaconda3/envs/graph_diffusion/lib/python3.8/subprocess.py\", line 1083, in wait\n",
      "    return self._wait(timeout=timeout)\n",
      "  File \"/home/lcosmo/anaconda3/envs/graph_diffusion/lib/python3.8/subprocess.py\", line 1822, in _wait\n",
      "    (pid, sts) = self._try_wait(0)\n",
      "  File \"/home/lcosmo/anaconda3/envs/graph_diffusion/lib/python3.8/subprocess.py\", line 1780, in _try_wait\n",
      "    (pid, sts) = os.waitpid(self.pid, wait_flags)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lcosmo/anaconda3/envs/graph_diffusion/lib/python3.8/site-packages/wandb/sdk/wandb_manager.py\", line 148, in _teardown\n",
      "    result = self._service.join()\n",
      "  File \"/home/lcosmo/anaconda3/envs/graph_diffusion/lib/python3.8/site-packages/wandb/sdk/service/service.py\", line 129, in join\n",
      "    ret = self._internal_proc.wait()\n",
      "  File \"/home/lcosmo/anaconda3/envs/graph_diffusion/lib/python3.8/subprocess.py\", line 1096, in wait\n",
      "    self._wait(timeout=sigint_timeout)\n",
      "  File \"/home/lcosmo/anaconda3/envs/graph_diffusion/lib/python3.8/subprocess.py\", line 1816, in _wait\n",
      "    time.sleep(delay)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python train_reconstruction.py --dataset=sbm_200 --k=8 --smallest=True --diffusion_model=3dn0ayuq --generator_layers=4 --generator_data_channels=64 --batch_size=16 \n",
      "python train_reconstruction.py --dataset=sbm_200 --k=8 --smallest=False --diffusion_model=3dn0ayuq --generator_layers=4 --generator_data_channels=64 --batch_size=16 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"train_reconstruction.py\", line 5, in <module>\n",
      "    import sklearn\n",
      "  File \"/home/lcosmo/anaconda3/envs/graph_diffusion/lib/python3.8/site-packages/sklearn/__init__.py\", line 82, in <module>\n",
      "    from .base import clone\n",
      "  File \"/home/lcosmo/anaconda3/envs/graph_diffusion/lib/python3.8/site-packages/sklearn/base.py\", line 13, in <module>\n",
      "    import numpy as np\n",
      "  File \"/home/lcosmo/anaconda3/envs/graph_diffusion/lib/python3.8/site-packages/numpy/__init__.py\", line 144, in <module>\n",
      "    from . import lib\n",
      "  File \"/home/lcosmo/anaconda3/envs/graph_diffusion/lib/python3.8/site-packages/numpy/lib/__init__.py\", line 26, in <module>\n",
      "    from . import index_tricks\n",
      "  File \"/home/lcosmo/anaconda3/envs/graph_diffusion/lib/python3.8/site-packages/numpy/lib/index_tricks.py\", line 13, in <module>\n",
      "    from .function_base import diff\n",
      "  File \"/home/lcosmo/anaconda3/envs/graph_diffusion/lib/python3.8/site-packages/numpy/lib/function_base.py\", line 5251, in <module>\n",
      "    def insert(arr, obj, values, axis=None):\n",
      "  File \"/home/lcosmo/anaconda3/envs/graph_diffusion/lib/python3.8/site-packages/numpy/core/overrides.py\", line 172, in decorator\n",
      "    verify_matching_signatures(implementation, dispatcher)\n",
      "  File \"/home/lcosmo/anaconda3/envs/graph_diffusion/lib/python3.8/site-packages/numpy/core/overrides.py\", line 90, in verify_matching_signatures\n",
      "    implementation_spec = ArgSpec(*getargspec(implementation))\n",
      "  File \"<string>\", line 1, in __new__\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"train_reconstruction.py\", line 5, in <module>\n",
      "    import sklearn\n",
      "  File \"/home/lcosmo/anaconda3/envs/graph_diffusion/lib/python3.8/site-packages/sklearn/__init__.py\", line 82, in <module>\n",
      "    from .base import clone\n",
      "  File \"/home/lcosmo/anaconda3/envs/graph_diffusion/lib/python3.8/site-packages/sklearn/base.py\", line 17, in <module>\n",
      "    from .utils import _IS_32BIT\n",
      "  File \"/home/lcosmo/anaconda3/envs/graph_diffusion/lib/python3.8/site-packages/sklearn/utils/__init__.py\", line 17, in <module>\n",
      "    from scipy.sparse import issparse\n",
      "  File \"/home/lcosmo/anaconda3/envs/graph_diffusion/lib/python3.8/site-packages/scipy/sparse/__init__.py\", line 283, in <module>\n",
      "    from . import csgraph\n",
      "  File \"/home/lcosmo/anaconda3/envs/graph_diffusion/lib/python3.8/site-packages/scipy/sparse/csgraph/__init__.py\", line 185, in <module>\n",
      "    from ._laplacian import laplacian\n",
      "  File \"/home/lcosmo/anaconda3/envs/graph_diffusion/lib/python3.8/site-packages/scipy/sparse/csgraph/_laplacian.py\", line 7, in <module>\n",
      "    from scipy.sparse.linalg import LinearOperator\n",
      "  File \"/home/lcosmo/anaconda3/envs/graph_diffusion/lib/python3.8/site-packages/scipy/sparse/linalg/__init__.py\", line 130, in <module>\n",
      "    from . import isolve, dsolve, interface, eigen, matfuncs\n",
      "  File \"<frozen importlib._bootstrap>\", line 991, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 975, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 671, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 839, in exec_module\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 923, in get_code\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 422, in cache_from_source\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 123, in _path_join\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python train_reconstruction.py --dataset=sbm_200 --k=16 --smallest=True --diffusion_model=3dn0ayuq --generator_layers=4 --generator_data_channels=64 --batch_size=16 \n",
      "python train_reconstruction.py --dataset=sbm_200 --k=16 --smallest=False --diffusion_model=3dn0ayuq --generator_layers=4 --generator_data_channels=64 --batch_size=16 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"train_reconstruction.py\", line 5, in <module>\n",
      "    import sklearn\n",
      "  File \"/home/lcosmo/anaconda3/envs/graph_diffusion/lib/python3.8/site-packages/sklearn/__init__.py\", line 82, in <module>\n",
      "    from .base import clone\n",
      "  File \"/home/lcosmo/anaconda3/envs/graph_diffusion/lib/python3.8/site-packages/sklearn/base.py\", line 17, in <module>\n",
      "    from .utils import _IS_32BIT\n",
      "  File \"/home/lcosmo/anaconda3/envs/graph_diffusion/lib/python3.8/site-packages/sklearn/utils/__init__.py\", line 17, in <module>\n",
      "    from scipy.sparse import issparse\n",
      "  File \"/home/lcosmo/anaconda3/envs/graph_diffusion/lib/python3.8/site-packages/scipy/sparse/__init__.py\", line 278, in <module>\n",
      "    from ._arrays import (\n",
      "  File \"/home/lcosmo/anaconda3/envs/graph_diffusion/lib/python3.8/site-packages/scipy/sparse/_arrays.py\", line 68, in <module>\n",
      "    class coo_array(_sparray, coo_matrix):\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "from itertools import product\n",
    "import random\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "os.environ[\"WANDB_MODE\"]=\"online\"\n",
    "\n",
    "diffusion_models = ['ytcfkbrz','2shqiia7'] #sbm\n",
    "diffusion_models = ['3dn0ayuq']\n",
    "rec_weights = [1e0]\n",
    "# # GAN arguments\n",
    "# parser.add_argument('--generator_layers', type=int, default=8)\n",
    "# parser.add_argument('--generator_data_channels', type=int, default=32)\n",
    "# parser.add_argument('--discriminator_layers', type=int, default=64)\n",
    "# parser.add_argument('--discriminator_data_channels', type=int, default=32)\n",
    "# parser.add_argument('--rec_weight', type=float, default=1e-1)\n",
    "\n",
    "\n",
    "combo = [[4, 64, 4, 16]]\n",
    "\n",
    "# combo = [[6, 64, 4, 32]]\n",
    "ks = [4,8,16,32]\n",
    "sms = [True,False]\n",
    "params = list(product(diffusion_models,rec_weights,combo,ks,sms))\n",
    "# random.shuffle(params)\n",
    "params\n",
    "dataset = 'sbm_200'\n",
    "batch_size=16\n",
    "\n",
    "for diffusion_model, rec_weight, (generator_layers,generator_data_channels,discriminator_layers,discriminator_data_channels), k, sm in params:\n",
    "    command = f'python train_reconstruction.py --dataset={dataset} --k={k} --smallest={sm} --diffusion_model={diffusion_model} --generator_layers={generator_layers} --generator_data_channels={generator_data_channels} --batch_size={batch_size} '\n",
    "    print(command)\n",
    "    os.system(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e605813",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2201754c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "import os\n",
    "from itertools import product\n",
    "import random\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "import argparse\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from utils.misc import *\n",
    "from utils.utils_score import *\n",
    "from dataset.load_data_generated import *\n",
    "\n",
    "from dataset.load_data_generated import *\n",
    "import sklearn.preprocessing \n",
    "\n",
    "from models.transformer import Transformer\n",
    "\n",
    "from models.reconstruction import Refiner2\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "from train_refiner import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8750a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = get_arg_parser().parse_args(['--diffusion_model','6mul37q1'])\n",
    "\n",
    "# #################### load diffusion_model ##############################\n",
    "# diffusion_model_path = glob.glob(f'graph_diffusion_perceptron/{args.diffusion_model}/checkpoints/epoch*.ckpt')[0]\n",
    "# model = Transformer.load_from_checkpoint(diffusion_model_path)\n",
    "\n",
    "# model.hparams.update(args.__dict__)\n",
    "# args = model.hparams\n",
    "# args.qm9 = args.dataset[:3] in [\"qm9\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "93ed8262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Point dim 16\n",
      "Tot #200\n",
      "compute graphs statistics\n",
      "computing degree:  tensor(0.0008)\n",
      "computing cluster:  tensor(0.0315)\n",
      "computing spectral:  tensor(0.0026)\n",
      "Point dim 16\n",
      "Tot #200\n"
     ]
    }
   ],
   "source": [
    "args.dataset='sbm_200'\n",
    "args.k=16\n",
    "args.smallest=True\n",
    "\n",
    "################### load real graphs training set ######################\n",
    "graphs_train_set = LaplacianDatasetNX(args.dataset,'data/'+args.dataset,point_dim=args.k, smallest=args.smallest, split='train', nodefeatures=args.dataset[:3] in [\"qm9\"])\n",
    "graphs_test_set = LaplacianDatasetNX(args.dataset,'data/'+args.dataset,point_dim=args.k, smallest=args.smallest, split='test', nodefeatures=args.dataset[:3] in [\"qm9\"])\n",
    "\n",
    "graphs_train_set.get_extra_data(False)\n",
    "\n",
    "graphs_train_set.get_extra_data()\n",
    "real_eval = torch.stack([t[1] for t in graphs_train_set],0)\n",
    "real_evec = torch.stack([t[0] for t in graphs_train_set],0)\n",
    "real_adj = torch.stack([t[-1][0] for t in graphs_train_set],0)\n",
    "\n",
    "real_emask = torch.stack([t[3] for t in graphs_train_set],0)\n",
    "real_edge_features = torch.stack([t[4] for t in graphs_train_set],0)\n",
    "\n",
    "mask = (real_evec.abs().sum(-1)>1e-5).float()\n",
    "real_evec,real_eval = graphs_train_set.unscale_xy(real_evec,real_eval)\n",
    "real_evec *= mask[:,:,None] \n",
    "real_evec *= real_emask[:,None,:] \n",
    "real_eval *= real_emask           \n",
    "\n",
    "\n",
    "train_set = torch.utils.data.TensorDataset(real_evec,real_eval,real_adj,real_edge_features)\n",
    "train_dataloader = DataLoader(train_set, batch_size=16, shuffle=True, num_workers=0,pin_memory=True)\n",
    "    \n",
    "################### load real graphs training set ######################\n",
    "graphs_test_set.get_extra_data()\n",
    "real_eval = torch.stack([t[1] for t in graphs_test_set],0)\n",
    "real_evec = torch.stack([t[0] for t in graphs_test_set],0)\n",
    "real_adj = torch.stack([t[-1][0] for t in graphs_test_set],0)\n",
    "\n",
    "real_emask = torch.stack([t[3] for t in graphs_test_set],0)\n",
    "real_edge_features = torch.stack([t[4] for t in graphs_test_set],0)\n",
    "\n",
    "mask = (real_evec.abs().sum(-1)>1e-5).float()\n",
    "real_evec,real_eval = graphs_train_set.unscale_xy(real_evec,real_eval)\n",
    "real_evec *= mask[:,:,None] \n",
    "real_evec *= real_emask[:,None,:] \n",
    "real_eval *= real_emask           \n",
    "real_eval = real_eval[:,None]\n",
    "\n",
    "val_set = torch.utils.data.TensorDataset(real_evec,real_eval,real_adj,real_edge_features)\n",
    "val_dataloader = DataLoader(ConcatDataset(graphs_test_set,val_set), batch_size=16, shuffle=True, num_workers=0,pin_memory=True)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e15a6bdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0108,  0.0063,  0.0088,  ..., -0.1197,  0.0219, -0.0967],\n",
       "        [-0.0281, -0.0182,  0.4296,  ..., -0.1372,  0.0362, -0.0967],\n",
       "        [-0.0080, -0.0075,  0.1106,  ..., -0.1331,  0.0349, -0.0967],\n",
       "        ...,\n",
       "        [ 0.0000, -0.0000,  0.0000,  ..., -0.0000, -0.0000,  0.0000],\n",
       "        [ 0.0000, -0.0000,  0.0000,  ..., -0.0000, -0.0000,  0.0000],\n",
       "        [ 0.0000, -0.0000,  0.0000,  ..., -0.0000, -0.0000,  0.0000]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_evec[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8a01fee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/2\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/2\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 2 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "ename": "ProcessRaisedException",
     "evalue": "\n\n-- Process 0 terminated with the following error:\nTraceback (most recent call last):\n  File \"/home/lcosmo/anaconda3/envs/graph_diffusion/lib/python3.8/site-packages/torch/multiprocessing/spawn.py\", line 69, in _wrap\n    fn(i, *args)\n  File \"/home/lcosmo/anaconda3/envs/graph_diffusion/lib/python3.8/site-packages/pytorch_lightning/strategies/launchers/multiprocessing.py\", line 133, in _wrapping_function\n    results = function(*args, **kwargs)\n  File \"/home/lcosmo/anaconda3/envs/graph_diffusion/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 735, in _fit_impl\n    results = self._run(model, ckpt_path=self.ckpt_path)\n  File \"/home/lcosmo/anaconda3/envs/graph_diffusion/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1102, in _run\n    self.strategy.setup_environment()\n  File \"/home/lcosmo/anaconda3/envs/graph_diffusion/lib/python3.8/site-packages/pytorch_lightning/strategies/strategy.py\", line 130, in setup_environment\n    self.accelerator.setup_environment(self.root_device)\n  File \"/home/lcosmo/anaconda3/envs/graph_diffusion/lib/python3.8/site-packages/pytorch_lightning/accelerators/cuda.py\", line 43, in setup_environment\n    torch.cuda.set_device(root_device)\n  File \"/home/lcosmo/anaconda3/envs/graph_diffusion/lib/python3.8/site-packages/torch/cuda/__init__.py\", line 314, in set_device\n    torch._C._cuda_setDevice(device)\n  File \"/home/lcosmo/anaconda3/envs/graph_diffusion/lib/python3.8/site-packages/torch/cuda/__init__.py\", line 207, in _lazy_init\n    raise RuntimeError(\nRuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mProcessRaisedException\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 41\u001b[0m\n\u001b[1;32m     27\u001b[0m args\u001b[38;5;241m.\u001b[39mcheck_val_every_n_epoch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     28\u001b[0m trainer \u001b[38;5;241m=\u001b[39m pl\u001b[38;5;241m.\u001b[39mTrainer\u001b[38;5;241m.\u001b[39mfrom_argparse_args(\n\u001b[1;32m     29\u001b[0m     args,\n\u001b[1;32m     30\u001b[0m     accelerator\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     38\u001b[0m     auto_lr_find\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     39\u001b[0m )\n\u001b[0;32m---> 41\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mref\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/graph_diffusion/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:696\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    678\u001b[0m \u001b[38;5;124;03mRuns the full optimization routine.\u001b[39;00m\n\u001b[1;32m    679\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    693\u001b[0m \u001b[38;5;124;03m    datamodule: An instance of :class:`~pytorch_lightning.core.datamodule.LightningDataModule`.\u001b[39;00m\n\u001b[1;32m    694\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    695\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m model\n\u001b[0;32m--> 696\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/graph_diffusion/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:648\u001b[0m, in \u001b[0;36mTrainer._call_and_handle_interrupt\u001b[0;34m(self, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    647\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 648\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlauncher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlaunch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    649\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    650\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/graph_diffusion/lib/python3.8/site-packages/pytorch_lightning/strategies/launchers/multiprocessing.py:107\u001b[0m, in \u001b[0;36m_MultiProcessingLauncher.launch\u001b[0;34m(self, function, trainer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    105\u001b[0m     process_args \u001b[38;5;241m=\u001b[39m [trainer, function, args, kwargs, return_queue]\n\u001b[0;32m--> 107\u001b[0m \u001b[43mmp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_processes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wrapping_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprocess_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnprocs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_strategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_processes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstart_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_start_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m worker_output \u001b[38;5;241m=\u001b[39m return_queue\u001b[38;5;241m.\u001b[39mget()\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trainer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/graph_diffusion/lib/python3.8/site-packages/torch/multiprocessing/spawn.py:198\u001b[0m, in \u001b[0;36mstart_processes\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m context\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# Loop on join until it returns True or raises an exception.\u001b[39;00m\n\u001b[0;32m--> 198\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/graph_diffusion/lib/python3.8/site-packages/torch/multiprocessing/spawn.py:160\u001b[0m, in \u001b[0;36mProcessContext.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    158\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m-- Process \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m terminated with the following error:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m error_index\n\u001b[1;32m    159\u001b[0m msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m original_trace\n\u001b[0;32m--> 160\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m ProcessRaisedException(msg, error_index, failed_process\u001b[38;5;241m.\u001b[39mpid)\n",
      "\u001b[0;31mProcessRaisedException\u001b[0m: \n\n-- Process 0 terminated with the following error:\nTraceback (most recent call last):\n  File \"/home/lcosmo/anaconda3/envs/graph_diffusion/lib/python3.8/site-packages/torch/multiprocessing/spawn.py\", line 69, in _wrap\n    fn(i, *args)\n  File \"/home/lcosmo/anaconda3/envs/graph_diffusion/lib/python3.8/site-packages/pytorch_lightning/strategies/launchers/multiprocessing.py\", line 133, in _wrapping_function\n    results = function(*args, **kwargs)\n  File \"/home/lcosmo/anaconda3/envs/graph_diffusion/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 735, in _fit_impl\n    results = self._run(model, ckpt_path=self.ckpt_path)\n  File \"/home/lcosmo/anaconda3/envs/graph_diffusion/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1102, in _run\n    self.strategy.setup_environment()\n  File \"/home/lcosmo/anaconda3/envs/graph_diffusion/lib/python3.8/site-packages/pytorch_lightning/strategies/strategy.py\", line 130, in setup_environment\n    self.accelerator.setup_environment(self.root_device)\n  File \"/home/lcosmo/anaconda3/envs/graph_diffusion/lib/python3.8/site-packages/pytorch_lightning/accelerators/cuda.py\", line 43, in setup_environment\n    torch.cuda.set_device(root_device)\n  File \"/home/lcosmo/anaconda3/envs/graph_diffusion/lib/python3.8/site-packages/torch/cuda/__init__.py\", line 314, in set_device\n    torch._C._cuda_setDevice(device)\n  File \"/home/lcosmo/anaconda3/envs/graph_diffusion/lib/python3.8/site-packages/torch/cuda/__init__.py\", line 207, in _lazy_init\n    raise RuntimeError(\nRuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method\n"
     ]
    }
   ],
   "source": [
    "\n",
    "###################################\n",
    "args.n_max = graphs_train_set.n_max\n",
    "ref = Refiner2(args)\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    save_last=True,\n",
    "    save_top_k=1,\n",
    "    verbose=True,\n",
    "    monitor='rec_loss',\n",
    "    mode='min'\n",
    ")\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor='rec_loss',\n",
    "    min_delta=0,\n",
    "    patience=20000,\n",
    "    verbose=False,\n",
    "    mode='min')\n",
    "\n",
    "wandb_logger = WandbLogger(\n",
    "    name=f\"{args.model_tag}_k-{args.k}_sm-{args.smallest}_dm-{args.diffusion_model}\",\n",
    "    project=\"graph_diffusion_refinement\",\n",
    "    entity=\"l_cosmo\",\n",
    "    offline=True\n",
    ")\n",
    "# wandb_logger=None\n",
    "\n",
    "args.check_val_every_n_epoch = None\n",
    "trainer = pl.Trainer.from_argparse_args(\n",
    "    args,\n",
    "    accelerator=\"auto\",\n",
    "    callbacks=[checkpoint_callback, early_stop_callback],\n",
    "    logger=wandb_logger,\n",
    "    log_every_n_steps=len(train_dataloader),\n",
    "    check_val_every_n_epoch = None,\n",
    "    val_check_interval = args.val_check_interval, \n",
    "    max_epochs = args.max_epochs,\n",
    "    auto_scale_batch_size=\"binsearch\",\n",
    "    auto_lr_find=True\n",
    ")\n",
    "\n",
    "trainer.fit(ref, train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d040fa54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 1, 32])\n",
      "torch.Size([8, 1, 32])\n",
      "torch.Size([8, 1, 32])\n",
      "torch.Size([8, 1, 32])\n",
      "torch.Size([8, 1, 32])\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'LaplacianDatasetNX' object has no attribute 'degree'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mref\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidation_epoch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/PROJECTS/Spectral-Graph-Diffusion/models/reconstruction.py:112\u001b[0m, in \u001b[0;36mRefiner2.validation_epoch_end\u001b[0;34m(self, outputs)\u001b[0m\n\u001b[1;32m    109\u001b[0m ori_train_set \u001b[38;5;241m=\u001b[39m gen_test_set \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mval_dataloaders[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39mdatasets[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    110\u001b[0m gen_test_set \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mval_dataloaders[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39mdatasets[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m--> 112\u001b[0m degree, cluster,  unique, novel, spectral, degree_degrad, cluster_degrad, spectral_degrad, avg_degrad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mori_train_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgen_test_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpowerful\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_lin\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdegree\u001b[39m\u001b[38;5;124m'\u001b[39m, torch\u001b[38;5;241m.\u001b[39mtensor(degree)\u001b[38;5;241m.\u001b[39mfloat(), on_step\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, on_epoch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcluster\u001b[39m\u001b[38;5;124m'\u001b[39m,  torch\u001b[38;5;241m.\u001b[39mtensor(cluster)\u001b[38;5;241m.\u001b[39mfloat(), on_step\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, on_epoch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/PROJECTS/Spectral-Graph-Diffusion/models/reconstruction.py:210\u001b[0m, in \u001b[0;36mRefiner2.evaluate\u001b[0;34m(self, train_set, test_set, device)\u001b[0m\n\u001b[1;32m    207\u001b[0m     unique,novel,_ \u001b[38;5;241m=\u001b[39m eval_fraction_unique_non_isomorphic_valid(graph_pred_list_remove_empty,graph_train_list)\n\u001b[1;32m    208\u001b[0m     spectral \u001b[38;5;241m=\u001b[39m spectral_stats(graph_test_list, graph_pred_list_remove_empty)\n\u001b[0;32m--> 210\u001b[0m degree_degrad \u001b[38;5;241m=\u001b[39m degree\u001b[38;5;241m/\u001b[39m\u001b[43mtrain_set\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdegree\u001b[49m\n\u001b[1;32m    211\u001b[0m cluster_degrad \u001b[38;5;241m=\u001b[39m cluster\u001b[38;5;241m/\u001b[39mtrain_set\u001b[38;5;241m.\u001b[39mcluster\n\u001b[1;32m    212\u001b[0m spectral_degrad \u001b[38;5;241m=\u001b[39m spectral\u001b[38;5;241m/\u001b[39mtrain_set\u001b[38;5;241m.\u001b[39mspectral\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'LaplacianDatasetNX' object has no attribute 'degree'"
     ]
    }
   ],
   "source": [
    "ref.validation_epoch_end([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d5cc2906",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataset.TensorDataset at 0x7f06c98a3670>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref.trainer.val_dataloaders[0].dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:graph_diffusion]",
   "language": "python",
   "name": "conda-env-graph_diffusion-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
